{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A (Possible?) Code for Identifying Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import Acqu (which parses the events?) and Timepix (which decodes the data??), as well as numpy, ROOT, and plotting classes of ROOT which allow us to organize and graph the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.16/00\n"
     ]
    }
   ],
   "source": [
    "import Acqu as aq\n",
    "import Timepix\n",
    "import numpy as np\n",
    "import ROOT\n",
    "from rootpy.plotting import Hist, Hist2D, histogram, Canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we import the data that was collected and open that data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mk2 Data\n"
     ]
    }
   ],
   "source": [
    "inFile = '/w/work0/mainz/2019_05_Timepix3-Acqu/Timepix_33.dat'\n",
    "aq.openFile(inFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting arrays of the data from each detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TimepixAData = []\n",
    "TimepixBData = []\n",
    "\n",
    "def plotTimepix():\n",
    "    if(aq.epicsEvent==1):\n",
    "        nHitsA       = aq.getEpicsPV('PPOL:TIMEPIXA:NHITS')\n",
    "        encodedA     = aq.getEpicsPV('PPOL:TIMEPIXA:ENCODED')\n",
    "        nHitsB       = aq.getEpicsPV('PPOL:TIMEPIXB:NHITS')\n",
    "        encodedB     = aq.getEpicsPV('PPOL:TIMEPIXB:ENCODED')\n",
    "        TimepixAData.append(Timepix.Decode(nHitsA,encodedA))\n",
    "        TimepixBData.append(Timepix.Decode(nHitsB,encodedB))       \n",
    "aq.runFunction(plotTimepix,0,50000)\n",
    "\n",
    "# do we need to sort the data first???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to/need to, we could loop through and make an array of just a certain value (say ToA):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "AData = []\n",
    "ToAA = []\n",
    "\n",
    "for i in range(len(TimepixAData)):\n",
    "    AData.append(TimepixAData[0]['ToA'])\n",
    "for j in range(len(AData)):\n",
    "    for k in range(len(AData[j])):\n",
    "        ToAA.append(AData[j][k])\n",
    "        \n",
    "BData = []\n",
    "ToAB = []\n",
    "\n",
    "for i in range(len(TimepixBData)):\n",
    "    BData.append(TimepixBData[0]['ToA'])\n",
    "for j in range(len(BData)):\n",
    "    for k in range(len(BData[j])):\n",
    "        ToAB.append(BData[j][k])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At some point we'll need to process the cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cluster():\n",
    "    start_index = cl[0] # start index of the 1st cluster hit\n",
    "    min_time = TimepixAData[0]['ToA'][start_index]# time (of arrival) of the first hit\n",
    "    #dtime = Null # time differences?\n",
    "    meanx = 0.0\n",
    "    meany = 0.0\n",
    "    \n",
    "    n = start_index\n",
    "    while(n<start_index+cn): # loop over the cluster to find the lowest time, etc. (for loop in Ken's code)\n",
    "        if(TimepixAData[0]['ToA'][n] < min_time): # if the time at this hit is less than the min time we've found\n",
    "            min_time = TimepixAData[0]['ToA'][n]# then set this lower value to the min time\n",
    "        meanx+=TimepixAData[0]['x'][n] # adding up all x positions\n",
    "        meany+=TimepixAData[0]['y'][n] # adding up all y positions\n",
    "        n+=1\n",
    "    \n",
    "    meanx/=cn # divide the sum of positions by number of hits to get the mean\n",
    "    meany/=cn # same as meanx, but for y\n",
    "    \n",
    "    ROOT.enableJSVis()\n",
    "    \n",
    "    d2pos = Hist2D(10,0,150,10,0,150)\n",
    "    d2pos.Fill(meanx,meany)\n",
    "    mult = Hist(100,0,100)\n",
    "    mult.Fill(nc)\n",
    "    \n",
    "    print(meanx, meany)\n",
    "    \n",
    "    c4 = ROOT.TCanvas(\"my4\",\"The Canvas Title\",1000,1000)\n",
    "    c4.Divide(2,1)\n",
    "    c4.cd(1)\n",
    "    d2pos.Draw(\"colz\")\n",
    "    c4.cd(2)\n",
    "    mult.Draw()\n",
    "    c4.Draw()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"process :)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to identify clusters. Note: I'm not sure how the data is organized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14.0, 25.0)\n",
      "process :)\n",
      "(171.0, 115.0)\n",
      "process :)\n",
      "(171.0, 115.0)\n",
      "process :)\n",
      "(92.0, 113.0)\n",
      "process :)\n",
      "(92.0, 113.0)\n",
      "process :)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clas12/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: overflow encountered in uint_scalars\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(93.0, 113.0)\n",
      "process :)\n",
      "(93.0, 113.0)\n",
      "process :)\n",
      "(153.0, 105.0)\n",
      "process :)\n",
      "(148.0, 230.0)\n",
      "process :)\n",
      "(181.0, 167.0)\n",
      "process :)\n",
      "(98.0, 98.0)\n",
      "process :)\n",
      "(99.0, 98.0)\n",
      "process :)\n",
      "(230.5, 0.0)\n",
      "process :)\n",
      "(230.0, 0.0)\n",
      "process :)\n",
      "(192.0, 184.0)\n",
      "process :)\n",
      "(251.0, 178.0)\n",
      "process :)\n",
      "(251.0, 178.0)\n",
      "process :)\n",
      "(167.0, 72.0)\n",
      "process :)\n",
      "(214.0, 125.0)\n",
      "process :)\n",
      "(217.25, 125.25)\n",
      "process :)\n",
      "(218.0, 125.0)\n",
      "process :)\n",
      "(203.0, 132.0)\n",
      "process :)\n",
      "(152.0, 91.0)\n",
      "process :)\n",
      "(153.0, 90.0)\n",
      "process :)\n",
      "(153.0, 90.0)\n",
      "process :)\n",
      "(185.0, 175.0)\n",
      "process :)\n",
      "(118.0, 158.0)\n",
      "process :)\n",
      "(118.0, 157.0)\n",
      "process :)\n",
      "(143.0, 170.0)\n",
      "process :)\n",
      "(119.0, 130.0)\n",
      "process :)\n",
      "(120.0, 130.0)\n",
      "process :)\n",
      "(156.0, 121.0)\n",
      "process :)\n",
      "(156.0, 121.0)\n",
      "process :)\n",
      "(157.0, 216.0)\n",
      "process :)\n",
      "(157.0, 215.0)\n",
      "process :)\n",
      "(150.0, 249.0)\n",
      "process :)\n",
      "(142.0, 119.0)\n",
      "process :)\n",
      "(143.0, 118.0)\n",
      "process :)\n",
      "(143.0, 118.0)\n",
      "process :)\n",
      "(136.0, 219.0)\n",
      "process :)\n",
      "(136.0, 219.0)\n",
      "process :)\n",
      "(244.0, 211.0)\n",
      "process :)\n",
      "(244.0, 210.0)\n",
      "process :)\n",
      "(151.0, 153.0)\n",
      "process :)\n",
      "(152.0, 153.0)\n",
      "process :)\n",
      "(190.0, 202.0)\n",
      "process :)\n",
      "(171.0, 250.0)\n",
      "process :)\n",
      "(172.0, 250.0)\n",
      "process :)\n",
      "(179.0, 148.0)\n",
      "process :)\n",
      "(179.0, 148.0)\n",
      "process :)\n",
      "(140.0, 204.0)\n",
      "process :)\n",
      "(175.0, 159.0)\n",
      "process :)\n",
      "(139.0, 204.0)\n",
      "process :)\n",
      "(139.0, 204.0)\n",
      "process :)\n",
      "(242.0, 32.0)\n",
      "process :)\n",
      "(242.0, 31.0)\n",
      "process :)\n",
      "(114.0, 104.0)\n",
      "process :)\n",
      "(114.0, 104.0)\n",
      "process :)\n",
      "(252.0, 116.0)\n",
      "process :)\n",
      "(253.0, 116.0)\n",
      "process :)\n",
      "(188.0, 215.0)\n",
      "process :)\n",
      "(188.5, 214.0)\n",
      "process :)\n",
      "(189.0, 214.0)\n",
      "process :)\n",
      "(188.5, 214.0)\n",
      "process :)\n",
      "(189.0, 214.0)\n",
      "process :)\n",
      "(189.0, 214.0)\n",
      "process :)\n",
      "(153.0, 123.5)\n",
      "process :)\n",
      "(153.0, 123.0)\n",
      "process :)\n",
      "(152.0, 122.0)\n",
      "process :)\n",
      "(152.16666666666666, 124.0)\n",
      "process :)\n",
      "(222.0, 86.0)\n",
      "process :)\n",
      "(146.0, 217.0)\n",
      "process :)\n",
      "(144.0, 217.0)\n",
      "process :)\n",
      "(144.66666666666666, 226.0)\n",
      "process :)\n",
      "(198.0, 11.0)\n",
      "process :)\n",
      "(198.0, 7.5)\n",
      "process :)\n",
      "(196.5, 10.5)\n",
      "process :)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-32758249e7d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mnc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m# zero the cluster counter - counts the number of clusters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mblen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# for every hit in the buffer (buffer position is less than the length of the buffer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mcl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;31m# assume this buffer position is the 1st hit in the current cluster, save it to this cluster's array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mcn\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;31m# and increment the counter of hits in this cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "cl = [None]*100 # holds up to 100 hits in a cluster, initialized as None\n",
    "cn = 0 # count number of hits in current cluster\n",
    "blen = 0 # length of current timepix3 buffer\n",
    "b = 0 # running buffer position\n",
    "\n",
    "blen = 100 #readTimepixBufferFromFile()\n",
    "while(blen): # read each timepix buffer into timepix3, except it does't work\n",
    "    nc = 0 # zero the cluster counter - counts the number of clusters\n",
    "    while(b<blen): # for every hit in the buffer (buffer position is less than the length of the buffer)\n",
    "        cl[cn] = b # assume this buffer position is the 1st hit in the current cluster, save it to this cluster's array\n",
    "        cn+=1 # and increment the counter of hits in this cluster\n",
    "        \n",
    "        c=b+1 # use c as a temporary buffer position to compare with\n",
    "        while((c<b+99) and c<blen): # check the next 99 to see if they are in the time window (for loop in Ken's code)\n",
    "            if(abs(TimepixAData[0]['ToA'][c]-TimepixAData[0]['ToA'][b])<100): # if within 100ns of other event in the cluster\n",
    "                cl[cn]=c # save the buffer position into this cluster's array\n",
    "                cn+=1 # increment the counter of hits in this cluster\n",
    "            else:\n",
    "                if cl[0]!= None:\n",
    "                    process_cluster() # do something with this cluster\n",
    "                b+=cn # move on to check beyond this cluster\n",
    "                cn = 0 # reset the number of hits for the new cluster\n",
    "                cl = [None]*100 # reset the array for the new cluster\n",
    "                nc += 1 # increment the number of clusters found\n",
    "            c+=1 # increment to the next buffer position\n",
    "    print(cl)\n",
    "    print(\"end\")\n",
    "    break\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
